import  pandas as pd
import numpy as np
from sklearn import ensemble
from sklearn import metrics
from sklearn import model_selection
from pathlib import Path
from sklearn import preprocessing
from sklearn import decomposition
from sklearn import pipeline
from functools import partial
from skopt import space
from skopt import gp_minimize

def optmize(params, param_names, x, y):
    params = dict(zip(param_names, params))

    model = ensemble.RandomForestClassifier(**params)
    kf =  model_selection.StratifiedKFold(n_splits=5)
    accuracies = []
    for idx in kf.split(X=x, y=y):
        train_idx, test_idx = idx[0],  idx[1]
        xtrain = x[train_idx]
        ytrain = y[train_idx]

        xtest = x[test_idx]
        ytest = y[test_idx]

        model.fit(xtrain, ytrain)
        preds = model.predict(xtest)
        fold_acc = metrics.accuracy_score(ytest, preds)
        accuracies.append(fold_acc)

    return -1.0 * np.mean(accuracies)


if __name__ == '__main__':
    train_file_path = Path("/Users/intellify-sarojdongol/workspace/scikit-learn/hyperparameter-optimization/input/train.csv")
    df = pd.read_csv(train_file_path)
    X_train = df.drop("price_range", axis=1).values
    X_train = df.price_range.values

    param_space = [
        space.Integer(3, 15, name="max_depth"),
        space.Integer(100,600, name="n_estimators"),
        space.Categorical(["gini", "entropy"], name="criterion"),
        space.Real(0.01, 1, prior="uniform", name="max_features")
    ]

    param_names = [
        "max_depth",
        "n_estimators",
        "criterion",
        "max_features"
    ]

    optmized_function = partial(
        optmize,
        param_names=param_names,
        x=X_train,
        y=X_train
    )

    result =  gp_minimize(
        optmized_function,
        dimensions=param_space,
        n_calls=15,
        n_random_starts=10,
        verbose=10
    )
    print(
        dict(zip(param_names, result.x))
    )